{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search for root_dir and set working directory\n",
      "Working directory set to: /mnt/ssd/git/wft21_septum_landmark_detection\n"
     ]
    }
   ],
   "source": [
    "# define logging and working directory\n",
    "from ProjectRoot import change_wd_to_project_root\n",
    "change_wd_to_project_root()\n",
    "from src.utils.Notebook_imports import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the main concepts of a DL generator\n",
    "\n",
    "A Generator yields a tuple of (x,y) and is used to feed data into a deep learning model\n",
    "\n",
    "Each tuple has the following shape: \n",
    "\n",
    "$(batchsize \\times inputObjects \\times inputShape)$ , $(batchsize \\times ioutputObjects \\times outputShape)$\n",
    "\n",
    "--> $inputShape$/$outputShape$ could be:\n",
    "- for 1D vector-data: $width$\n",
    "- for 2D images: $height \\times width$: \n",
    "- for 3D volumes: $depth \\times height \\times width$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create fake data interactively\n",
    "\n",
    "Please define:\n",
    "\n",
    "- $examples$ - The total number of patients (the size of the dataset)\n",
    "- $inputObjects$ / $ouputObjects$ - This could be the timesteps of 4D CMR files or the number of 3D volumes/ different modalities (multi-input model)\n",
    "- $inputShape$ / $outputShape$ - could be 3/2 or 1D data, e.g.>: 𝑑𝑒𝑝𝑡ℎ∗ℎ𝑒𝑖𝑔ℎ𝑡∗𝑤𝑖𝑑𝑡ℎ.\n",
    "- $batchsize$ -  Which is the number of entities yielded in one step\n",
    "\n",
    "Usually the generator would save only the references to the corresponding files.\n",
    "In this example we create numpy arrays with the desired shape on the fly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6de5732c48e743599419fbd62cde1a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=100, description='examples_', max=200, min=1), IntSlider(value=4, descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the size of our fake data\n",
    "upper_example_limit = 200\n",
    "upper_example_size_limit = 8\n",
    "upper_batchsize_limit = 20\n",
    "\n",
    "@interact_manual\n",
    "def create_fake_data(examples_=(1,upper_example_limit), \n",
    "                     inputObjects=(1,upper_example_size_limit),\n",
    "                     outputObjects=(1,upper_example_size_limit),\n",
    "                     batchsize_=(1,upper_batchsize_limit), \n",
    "                     input_obj_shape='(10,10,10)', \n",
    "                     ouptut_obj_shape='(10,10,10)'):\n",
    "    \n",
    "    global examples, input_objects, output_objects , batchsize, indexes, X, Y, x_dict, y_dict, batches\n",
    "    examples = examples_\n",
    "    batchsize = batchsize_\n",
    "    input_objects = inputObjects\n",
    "    output_objects = outputObjects\n",
    "    \n",
    "    # make sure the dimensions have the correct formating\n",
    "    # converts a string of int-tuple into a tuple of int '(10,10,10)' --> (10,10,10)\n",
    "    x_dim = tuple(map(int, input_obj_shape.replace(')', '').replace('(','').split(',')))\n",
    "    y_dim = tuple(map(int, ouptut_obj_shape.replace(')', '').replace('(','').split(',')))\n",
    "    \n",
    "    # create some fake data\n",
    "    x_dict = {}\n",
    "    y_dict = {}  \n",
    "    for example in range(examples_):\n",
    "        # create example data (batchsize x input_objects x input_object_shape and batchsize output_objects x output_object_shape)\n",
    "        # squeeze unused dimensions\n",
    "        x_dict[example] = np.squeeze(np.stack([np.round(np.random.sample(x_dim),2)+example for i in range(input_objects)]))\n",
    "        y_dict[example] = np.squeeze(np.stack([np.round(np.random.sample(y_dim),2)+(10*example) for i in range(output_objects)]))\n",
    "        # testing purpose if lists are faster than dicts\n",
    "        #X.append(np.stack([np.round(np.random.sample(x_dim),2)+example for i in range(input_objects)]))\n",
    "    # index our data, we can use the indicies to select one example or a batch of examples from a list or dictionary\n",
    "    # By this we dont need to shuffle the data itself, we shuffle only the indexes\n",
    "    indexes = list(range(len(x_dict)))\n",
    "    batches = int(np.floor(examples/batchsize))-1\n",
    "    print('Shape of one batch X: {} * {}, Y: {} * {}'.format(batchsize, x_dict[0].shape, batchsize, y_dict[0].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select one batch and yield the corresponding values/shape $(batchsize \\times inputObjects \\times inputObjShape),(batchsize \\times outputObjects \\times outputObjShape)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c7ec740075541a5a5eb12d8be6348ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=4, description='selected_batch', max=9), Checkbox(value=False, descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def select_batch(selected_batch = (0,batches), shuffle_indexes=False, debug=False):\n",
    "    global indexes\n",
    "    \n",
    "    if shuffle_indexes:\n",
    "        random.shuffle(indexes)\n",
    "    # make sure indexes are correctly initialised\n",
    "    assert len(indexes) == examples, print('len indexes: {}, number of examples: {}'.format(len(indexes), examples))\n",
    "    \n",
    "    # define the lower/upper index slicing borders of the current batch\n",
    "    start_idx = selected_batch*batchsize\n",
    "    end_idx = (selected_batch+1)*batchsize\n",
    "    \n",
    "    # we slice the indexes of the current batch from the index list\n",
    "    batch_indexes = indexes[start_idx: end_idx]\n",
    "    \n",
    "    # print the restrictions of the current batch\n",
    "    print('selected batch: {} of {} with a batchsize of {} and total {} examples'.format(selected_batch, batches, batchsize, examples))\n",
    "    print('start idx: {}, end idx: {}'.format(start_idx, end_idx))\n",
    "    print('Indexes of the currrent batch: {}'.format(batch_indexes))\n",
    "    print('-'*40)\n",
    "    \n",
    "    # stack the entities of the current batch\n",
    "    batch_x = np.stack([x_dict[k] for k in batch_indexes])\n",
    "    batch_y = np.stack([y_dict[k] for k in batch_indexes])\n",
    "    if debug:\n",
    "        [print('index: {}: value: {}'.format(k, x_dict[k])) for k in batch_indexes]\n",
    "        [print('index: {}: value: {}'.format(k, y_dict[k])) for k in batch_indexes]\n",
    "    \n",
    "    return([batch_x.shape, batch_y.shape])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple random generator, subclassed from tensorflow.keras.utils.Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow, random\n",
    "from time import time\n",
    "import concurrent.futures\n",
    "from concurrent.futures import as_completed\n",
    "import logging\n",
    "from src.utils.Utils_io import Console_and_file_logger\n",
    "\n",
    "class BaseGenerator(tensorflow.keras.utils.Sequence):\n",
    "    \"\"\"\n",
    "    Base generator class\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, x=None, y=None, config={}):\n",
    "        \"\"\"\n",
    "        Creates a base datagenerator for a list of nrrd images and a list of nrrd masks\n",
    "        :param x: list of nrrd image file names\n",
    "        :param y: list of nrrd mask file names\n",
    "        :param config:\n",
    "        \"\"\"\n",
    "        # Define standard parameters\n",
    "        # ###################################################################\n",
    "        logging.info('Create BaseDataGenerator')\n",
    "        assert len(x) == len(y)\n",
    "\n",
    "        self.EXAMPLES = len(x)\n",
    "        self.INPUTS = config.get('INPUTS', 1)\n",
    "        self.OUTPUTS = config.get('OUTPUTS', 1)\n",
    "        self.X_DIM = str(config.get('X_DIM', (256, 256)))\n",
    "        self.Y_DIM = str(config.get('Y_DIM', (256, 256)))\n",
    "        self.BATCHSIZE = config.get('BATCHSIZE', 32)\n",
    "        self.SHUFFLE = config.get('SHUFFLE', True)\n",
    "        \n",
    "        # create one worker per image & mask (batchsize) for parallel pre-processing if nothing else is defined\n",
    "        self.MAX_WORKERS = config.get('MAX_WORKERS', self.BATCHSIZE)\n",
    "        self.MAX_WORKERS = min(32, self.MAX_WORKERS)\n",
    "\n",
    "        # Make sure the dimensions have the correct formating\n",
    "        # converts a string of int-tuple into a tuple of int '(10,10,10)' --> (10,10,10), or 10 --> (10,)\n",
    "        self.X_DIM = tuple(map(int, self.X_DIM.replace(')', '').replace('(', '').split(',')))\n",
    "        self.Y_DIM = tuple(map(int, self.Y_DIM.replace(')', '').replace('(', '').split(',')))\n",
    "\n",
    "        # Create some static fake data\n",
    "        # #######################################################################\n",
    "        self.x_dict = {}\n",
    "        self.y_dict = {}\n",
    "        for example in range(self.EXAMPLES):\n",
    "            # create example data (batchsize x input_objects x input_object_shape and batchsize output_objects x output_object_shape)\n",
    "            # squeeze unused dimensions\n",
    "            self.x_dict[example] = np.squeeze(\n",
    "                np.stack([np.round(np.random.sample(self.X_DIM), 2) + example for i in range(self.INPUTS)]))\n",
    "            self.y_dict[example] = np.squeeze(\n",
    "                np.stack([np.round(np.random.sample(self.Y_DIM), 2) + (10 * example) for i in range(self.OUTPUTS)]))\n",
    "        # #######################################################################\n",
    "        # index our data, we can use the indicies to select one example or a batch of examples from a list or dictionary\n",
    "        # By this we dont need to shuffle the data itself, we shuffle only the indexes\n",
    "        \n",
    "        # We use these indicies to access and shuffle the data\n",
    "        # #######################################################################\n",
    "        self.INDICES = list(range(len(self.x_dict)))\n",
    "\n",
    "        print('Shape of one batch X: {} * {}, Y: {} * {}'.format(self.BATCHSIZE, self.x_dict[0].shape, self.BATCHSIZE,\n",
    "                                                                 self.y_dict[0].shape))\n",
    "        \n",
    "        self.X_SHAPE = np.empty((self.BATCHSIZE, *self.x_dict[0].shape), dtype=np.float32)\n",
    "        self.Y_SHAPE = np.empty((self.BATCHSIZE, *self.y_dict[0].shape), dtype=np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Denotes the number of batches per epoch\n",
    "        :return: number of batches\n",
    "        \"\"\"\n",
    "        return int(np.floor(len(self.INDICES) / self.BATCHSIZE))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        \"\"\"\n",
    "        Generate the indexes for one batch of data\n",
    "        This method allows to access the gen by simple indices\n",
    "        gen = BaseGenerator(...)\n",
    "        x,y = gen[0]\n",
    "        :param index: int in the range of  {0: len(dataset)/Batchsize}\n",
    "        :return: pre-processed batch as x,y tuples\n",
    "        \"\"\"\n",
    "\n",
    "        t0 = time()\n",
    "        # collect n indices with n = Batchsize\n",
    "        # starting from the given index parameter\n",
    "        # which is in the range of  {0: len(dataset)/Batchsize}\n",
    "        idxs = self.INDICES[index * self.BATCHSIZE: (index + 1) * self.BATCHSIZE]\n",
    "\n",
    "        return self.__data_generation__(idxs)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Shuffle the indexes after each epoch\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "\n",
    "        if self.SHUFFLE:\n",
    "            np.random.shuffle(self.INDICES)\n",
    "\n",
    "    def __data_generation__(self, ids):\n",
    "\n",
    "        \"\"\"\n",
    "        Preprocess one batch, represented by the list of ids\n",
    "        Could pre-process each entity in parallel\n",
    "        returns the preprocessed batch\n",
    "\n",
    "        :param list_IDs_temp:\n",
    "        :return: X : (batchsize, *dim, n_channels), Y : (batchsize, *dim, number_of_classes)\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialization\n",
    "\n",
    "        x = np.empty_like(self.X_SHAPE)\n",
    "        y = np.empty_like(self.Y_SHAPE)\n",
    "        logging.info('preprocess one batch with: {}, {}'.format(x.shape, y.shape))\n",
    "\n",
    "        futures = set()\n",
    "\n",
    "        # spawn one thread per worker\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=self.MAX_WORKERS) as executor:\n",
    "\n",
    "            t0 = time()\n",
    "            # Generate data\n",
    "            for i, ID in enumerate(ids):\n",
    "\n",
    "                try:\n",
    "                    # keep ordering of the shuffled indexes\n",
    "                    futures.add(executor.submit(self.__preprocess_one_image__, i, ID))\n",
    "\n",
    "                except Exception as e:\n",
    "                    logging.error(\n",
    "                        'Exception {} in datagenerator with: image: {} or mask: {}'.format(str(e), self.x_dict[ID],\n",
    "                                                                                           self.y_dict[ID]))\n",
    "        # This is out of the threadPool executor context\n",
    "        for i, future in enumerate(as_completed(futures)):\n",
    "            # use the index i to place each processed example in the batch\n",
    "            # otherwise slower images will always be at the end of the batch\n",
    "            # Use the ID for exception handling as reference to the file name\n",
    "            try:\n",
    "                x_, y_, i, ID, needed_time = future.result()\n",
    "                x[i,], y[i,] = x_, y_\n",
    "                logging.info('img finished after {:0.3f} sec.'.format(needed_time))\n",
    "            except Exception as e:\n",
    "                logging.error(\n",
    "                    'Exception {} in datagenerator with: image: {} or mask: {}'.format(str(e), self.x_dict[ID],\n",
    "                                                                                       self.y_dict[ID]))\n",
    "\n",
    "        logging.debug('Batchsize: {} preprocessing took: {:0.3f} sec'.format(self.BATCHSIZE, time() - t0))\n",
    "\n",
    "        return np.array(x.astype(np.float32)), np.array(y.astype(np.float32))\n",
    "\n",
    "    def __preprocess_one_image__(self, i, ID):\n",
    "        t0 = time()\n",
    "        import time as t\n",
    "        #t.sleep(1) # testing purpose\n",
    "        # in this function we would load and preprocess the file self.x_dict[ID] and self.y_dict[ID]\n",
    "        return self.x_dict[ID], self.y_dict[ID], i, ID, time() - t0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play here with the generator/config params\n",
    "\n",
    "The generator should follow the convention over configuration paradigm and provide a standard value for each possible parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of one batch X: 5 * (5, 5), Y: 5 * (5, 5)\n"
     ]
    }
   ],
   "source": [
    "cfg = {}\n",
    "cfg['X_DIM'] = 5,5\n",
    "cfg['Y_DIM'] = 5,5\n",
    "cfg['BATCHSIZE'] = 5\n",
    "cfg['MAX_WORKERS'] = 5\n",
    "files = 10\n",
    "gen = BaseGenerator(x=[1]*files,y=[1]*files, config=cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "139b0289e90a41b394a1cf6dbfbbe3fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='i', max=2), Checkbox(value=False, description='epoch_end…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def get_batches_from_generator(i=(0,len(gen)), epoch_end=False):\n",
    "    global gen\n",
    "    if epoch_end:gen.on_epoch_end()\n",
    "    x,y = gen[i]\n",
    "    print('x-shape: {}, y-shape: {}'.format(x.shape, y.shape))\n",
    "    print('mean x: {}, mean y: {}'.format(x.mean(), y.mean()))\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance of different indexing methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.01 s ± 1.09 ms per loop (mean ± std. dev. of 2 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 1\n",
    "# process all files of the generator\n",
    "_ = [(x,y) for x,y in gen]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subclassing new generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(BaseGenerator):\n",
    "    \"\"\"\n",
    "    Yields (X, Y) / image,mask for 2D and 3D U-net training\n",
    "    could be used to yield (X, None)\n",
    "    \"\"\"\n",
    "        \n",
    "    def __preprocess_one_image__(self, i, ID):\n",
    "        delta = 0.1\n",
    "        \n",
    "        # Add here any fancy new \n",
    "        \n",
    "        return self.x_dict[ID]*delta, self.y_dict[ID]*delta, i, ID, time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of one batch X: 5 * (5, 5), Y: 5 * (5, 5)\n"
     ]
    }
   ],
   "source": [
    "gen = DataGenerator(x=[1]*files,y=[1]*files, config=cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[2.78580580e+33, 3.07556987e-41, 0.00000000e+00, 0.00000000e+00,\n",
       "                     nan],\n",
       "         [4.58743078e-41, 1.63729959e-19, 1.14468136e+24, 2.56410238e+29,\n",
       "          6.13169348e+28],\n",
       "         [1.94209412e+31, 7.33822581e+34, 6.86081970e+22, 1.27715149e+01,\n",
       "          3.45812815e+12],\n",
       "         [1.15299647e+27, 6.65319884e-33, 1.14468136e+24, 5.08488755e+31,\n",
       "          4.96401942e+28],\n",
       "         [3.04812811e+32, 1.89427093e+23, 2.01115550e-19, 1.94316151e-19,\n",
       "          7.68133284e+31]],\n",
       " \n",
       "        [[7.22507385e+28, 2.28396210e+02, 2.00258371e-19, 6.74221921e+22,\n",
       "          1.75892947e+22],\n",
       "         [6.86081970e+22, 1.04630877e+27, 1.89808543e+28, 1.76668287e+22,\n",
       "          9.49574173e+12],\n",
       "         [2.82191761e+26, 4.61141998e+24, 6.26087042e+22, 4.74281365e+30,\n",
       "          4.85607420e+33],\n",
       "         [4.54177956e+30, 4.96401895e+28, 3.24870624e+33, 4.29568637e+24,\n",
       "          1.13616057e+30],\n",
       "         [7.15473767e+22, 1.80373090e+28, 1.93680168e+31, 1.95185260e-19,\n",
       "          7.00785457e+22]],\n",
       " \n",
       "        [[3.08808616e+29, 5.08488755e+31, 6.67408200e+22, 2.72594054e+20,\n",
       "          1.93458972e-19],\n",
       "         [5.08427342e+31, 3.02979701e+24, 3.47385640e-12, 6.86081970e+22,\n",
       "          1.04630877e+27],\n",
       "         [4.54179921e+30, 4.96401895e+28, 2.61859267e+20, 6.99874424e+22,\n",
       "          1.94312817e-19],\n",
       "         [3.04782869e+32, 4.96571758e+28, 1.08864523e+27, 7.92236267e+34,\n",
       "          2.06164635e-19],\n",
       "         [1.77495894e+28, 2.72594054e+20, 1.93458972e-19, 5.08427342e+31,\n",
       "          1.18351446e+22]],\n",
       " \n",
       "        [[4.30662259e+21, 2.75189255e+12, 2.06177766e-19, 1.16343462e+33,\n",
       "          1.93658371e+31],\n",
       "         [6.86081970e+22, 6.77158358e+22, 7.12207101e+28, 7.02923212e+28,\n",
       "          4.96644105e+28],\n",
       "         [2.79463838e+20, 1.85236006e+28, 1.21023773e+25, 2.76748132e+20,\n",
       "          4.30648214e+21],\n",
       "         [4.46497560e+30, 6.86116558e+22, 1.74183331e+28, 1.27715149e+01,\n",
       "          2.99656385e+32],\n",
       "         [4.54482213e+30, 1.78585617e+31, 7.55553492e+31, 4.95782887e+28,\n",
       "          3.04812811e+32]],\n",
       " \n",
       "        [[1.47765735e-19, 1.94315738e-19, 2.72487463e+20, 1.14468136e+24,\n",
       "          3.03451960e+29],\n",
       "         [7.06557856e+22, 7.36966610e+28, 2.67524866e+20, 1.84924380e+20,\n",
       "          1.09026456e+27],\n",
       "         [1.68793484e+25, 1.86105146e+34, 7.77811654e+31, 2.07064607e-19,\n",
       "          7.14346530e+31],\n",
       "         [6.74149233e+22, 2.75614785e+23, 2.06164544e-19, 1.94316151e-19,\n",
       "          1.89678370e+31],\n",
       "         [1.21218409e+25, 7.77827805e+31, 3.65178380e-42, 0.00000000e+00,\n",
       "          8.96831017e-43]]], dtype=float32),\n",
       " array([[[8.79162733e+32, 3.07556987e-41, 0.00000000e+00, 0.00000000e+00,\n",
       "                     nan],\n",
       "         [5.37422664e-30, 7.74555871e+31, 1.69576131e-10, 5.01919787e+33,\n",
       "          1.77531300e+28],\n",
       "         [2.86217141e+23, 5.62602603e-11, 2.10499826e-10, 2.86170970e+23,\n",
       "          2.73757760e+20],\n",
       "         [2.08627532e-10, 2.05021666e-10, 4.54451143e+30, 7.22507008e+28,\n",
       "          7.18309639e+22],\n",
       "         [7.55458180e+31, 1.31941073e-17, 2.74942013e+20, 2.88278729e+32,\n",
       "          7.14296819e+31]],\n",
       " \n",
       "        [[1.78657143e+25, 3.14676167e-11, 1.04470154e+27, 1.92861081e+28,\n",
       "          4.30597295e+21],\n",
       "         [2.63372002e+20, 1.02224979e+27, 1.94299466e-19, 7.03621104e+22,\n",
       "          7.21284357e+22],\n",
       "         [1.90689779e-19, 3.08541429e+32, 3.25440943e+33, 4.29568637e+24,\n",
       "          2.06176836e-19],\n",
       "         [1.94316151e-19, 2.99648145e+32, 2.82310791e+23, 6.86081970e+22,\n",
       "          1.80565538e+28],\n",
       "         [7.04604347e+19, 7.09635166e+22, 1.75893871e+22, 1.86722878e+25,\n",
       "          1.84937856e+20]],\n",
       " \n",
       "        [[1.78656347e+25, 2.03326139e+32, 7.14296819e+31, 1.21251561e+33,\n",
       "          4.90118988e+30],\n",
       "         [7.21503006e+22, 7.13454923e+31, 1.80565538e+28, 6.71200816e+22,\n",
       "          1.47702857e-19],\n",
       "         [1.94315738e-19, 2.79041594e+29, 2.82310791e+23, 3.03760142e+29,\n",
       "          7.21283726e+22],\n",
       "         [6.73056839e+22, 4.68862635e+27, 1.81774195e+31, 6.86081970e+22,\n",
       "          2.67996266e+20],\n",
       "         [4.96402320e+28, 4.61142027e+24, 3.08199506e+32, 4.46009547e+30,\n",
       "          2.11233623e-19]],\n",
       " \n",
       "        [[5.08328307e+31, 3.17697243e+30, 1.18692704e+27, 4.66809270e+24,\n",
       "          1.96840564e-19],\n",
       "         [2.03395579e+32, 7.14296819e+31, 1.47715910e-19, 1.94315738e-19,\n",
       "          2.79041594e+29],\n",
       "         [2.82209334e+23, 1.75916006e+22, 1.81740152e+31, 1.94446724e+31,\n",
       "          6.67408425e+22],\n",
       "         [1.74430240e+28, 4.61734943e-02, 1.45852208e-19, 4.61681162e+24,\n",
       "          4.51444069e+27],\n",
       "         [1.83931436e+25, 1.27106835e+31, 1.94375566e-19, 2.82976452e+20,\n",
       "          7.55535380e+28]],\n",
       " \n",
       "        [[6.86081970e+22, 1.74430240e+28, 2.82310899e+23, 1.80565538e+28,\n",
       "          7.04604347e+19],\n",
       "         [1.41352719e+05, 1.10462535e+27, 1.96029927e-19, 4.96414362e+28,\n",
       "          5.36816946e+28],\n",
       "         [6.99984956e+28, 1.80982058e+31, 1.78656347e+25, 1.21191823e+25,\n",
       "          4.30532809e+21],\n",
       "         [1.21233167e+25, 4.50932725e+27, 4.43769751e+27, 2.81810020e+20,\n",
       "          1.85236006e+28],\n",
       "         [2.70817460e+23, 1.69290411e+22, 6.44597294e-44, 0.00000000e+00,\n",
       "          8.96831017e-43]]], dtype=float32))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self, **kwargs):\n",
    "        super(self.__class__, self).__init__(**kwargs)\n",
    "        self.name = 'myfirstgenerator'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "# We have a list --> X and a dictionary --> x_dict, \n",
    "# len(X) == len(x_dict)\n",
    "# and X[i] == x_dict[i] for all i in range(len(X))\n",
    "# We create n random indicies within the range of len(X)\n",
    "samples = [randint(0, examples-1) for _ in range(10000000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248 ms ± 2.87 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# access the list n times, append the value to a new list\n",
    "temp = None\n",
    "for i in samples:\n",
    "    temp = X[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398 ms ± 2.14 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# access the dict n times, append the value to a new list\n",
    "temp = None\n",
    "for i in samples:\n",
    "    temp = x_dict[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dcmr",
   "language": "python",
   "name": "dcmr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
